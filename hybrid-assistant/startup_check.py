#!/usr/bin/env python3

import os
import sys
from pathlib import Path

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).parent))

from offline_handler import offline_manager

def print_header(text):
    print(f"\n{'='*60}")
    print(f"  {text}")
    print(f"{'='*60}\n")

def check_python_deps():
    """Check if core Python dependencies are installed"""
    required = {
        'torch': 'PyTorch',
        'cv2': 'OpenCV',
        'PIL': 'Pillow',
        'numpy': 'NumPy',
    }
    
    missing = []
    for module, name in required.items():
        try:
            __import__(module)
        except ImportError:
            missing.append(name)
    
    return len(missing) == 0, missing

def check_prerequisites():
    """Check all prerequisites before launch"""
    print_header("üîç HYBRID ASSISTANT - PRE-FLIGHT CHECKS")
    
    all_passed = True
    
    # 1. Internet check
    print("1Ô∏è‚É£  Checking internet connection...")
    internet = offline_manager.check_internet()
    if internet:
        print("   ‚úÖ Internet available\n")
    else:
        print("   ‚ö†Ô∏è  Running in offline mode\n")
    
    # 2. Python dependencies
    print("2Ô∏è‚É£  Checking Python dependencies...")
    deps_ok, missing = check_python_deps()
    if deps_ok:
        print("   ‚úÖ All core dependencies installed\n")
    else:
        print(f"   ‚ùå Missing: {', '.join(missing)}")
        print("   üìå Run: pip install -r requirements.txt\n")
        all_passed = False
    
    # 3. Ollama check
    print("3Ô∏è‚É£  Checking Ollama server...")
    ollama_running = offline_manager.verify_ollama()
    if ollama_running:
        print("   ‚úÖ Ollama running at http://localhost:11434")
        models = offline_manager.get_ollama_models()
        if models:
            print(f"   üì¶ Available models: {', '.join(models[:3])}")
            if len(models) > 3:
                print(f"      ... and {len(models) - 3} more\n")
            else:
                print()
        else:
            print("   ‚ö†Ô∏è  No models available\n")
    else:
        print("   ‚ùå Ollama NOT running!")
        print("   üìå Start Ollama with: ollama serve\n")
        all_passed = False
    
    # 4. Model cache check
    print("4Ô∏è‚É£  Checking cached models...")
    cache_dir = Path(os.environ.get('HF_HOME', Path.home() / '.cache' / 'huggingface'))
    cache_size = offline_manager.get_cache_size()
    
    if cache_dir.exists() and list(cache_dir.glob('**/*')):
        print(f"   ‚úÖ Models cached ({cache_size})\n")
    else:
        if internet:
            print("   ‚ìò Models not cached (will download on first run)\n")
        else:
            print("   ‚ö†Ô∏è  Models not cached and no internet available!")
            print("   üìå First run requires internet to download models\n")
            all_passed = False
    
    # Summary
    print_header("‚úÖ PRE-FLIGHT CHECK COMPLETE")
    
    if all_passed:
        print("‚ú® All checks passed! Ready to launch.\n")
        return 0
    else:
        print("‚ö†Ô∏è  Some checks failed. See above for details.\n")
        return 1

if __name__ == "__main__":
    exit_code = check_prerequisites()
    sys.exit(exit_code)
